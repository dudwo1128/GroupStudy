{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron \n",
    "- Binary Classification을 위한 \"Linear\" 모델\n",
    "- XOR 문제를 해결 할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks(ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러개의 Perceptron으로 구성\n",
    "- Perceptron의 한계를 해결 할 수 있음\n",
    "- NonLinear 모델\n",
    "- Classification과 Regression에 활용\n",
    "\n",
    "\n",
    "- Perceptron = 1 단위의 Neuron\n",
    "- ANN = Neural Net = 뇌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Decision Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/4가지.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron으로 AND/ NAND/ OR/ 해결 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR의 조건 2가지\n",
    " 1. 최소 하나의 입력값이 1이어야 한다 = OR의 특성\n",
    " 2. 입력값 모두 1이면 안된다 = NAND의 특성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR의 조합\n",
    "![title](images/XOR1.jpg)\n",
    "![title](images/XOR2.jpg) \n",
    "\n",
    "A XOR B = (A OR B) AND (A NAND B) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward and feedback artificial neural networks\n",
    "\n",
    "### ANN의 3가지 구성요소\n",
    "1. Architecture\n",
    "2. Activation Function\n",
    "3. Learning algoritm : 최적의 해를 찾음\n",
    "\n",
    "### ANN의 종류 2가지\n",
    "1. Feedforward Neural Network(순방향 신경망)\n",
    "\n",
    "    입력 데이터는 모든 노드를 딱 한번만 거쳐 출력층에 출력\n",
    "\n",
    "2. Recurrent Neural Network(순환 신경망)\n",
    "\n",
    "    가장 보편적으로 사용\n",
    "    \n",
    "    하지만 Scikit-Learn에는 포함되어 있지 않으니 본 장에서는 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptrons(MLP)\n",
    "\n",
    "\n",
    "![title](images/Overall.jpg) \n",
    "\n",
    "1. MLP는 가장 보편적으로 사용되는 ANN\n",
    "2. Layer에는 다음 Layer의 모든 노드와 연결되어 있음\n",
    "3. 3개 이상의 Layer를 포함하고 있음\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "구성요소\n",
    "1. Input Layer : 입력값 뉴런\n",
    "2. Hidden Layer : Latent Variables 나타냄/ Training Data에서 관측 불가 \n",
    "3. Output Layer : 마지막 Hidden Layer과 연결\n",
    "4. +1 Bias neurons : 보통 Diagram에서 나타내지 않음\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hidden Layer에서 활용하는 Nonlinear Activation Functions\n",
    "\n",
    "![title](images/function1.jpg) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "지도 학습이기 때문에 Cost Function을 최소화 하는 것이 목표\n",
    "![title](images/function2.jpg) \n",
    "\n",
    "\n",
    "- m = Training Instances의 개수 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing the cost function - Backpropagation(역전파)\n",
    "- 최적화 알고리듬\n",
    "- 네트워크 내 Error 흐름\n",
    "- Feedforward Network의 Hidden units을 Train하기 위함\n",
    "- Gradient Descent와 유사(Cost Function의 기울기를 업데이트하기 위함)\n",
    "- Hidden Units은 Latent Variables를 포함하고 있음\n",
    "- Hidden Units이 정확히 어떤 영향을 주는지 알수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "![title](images/ForwardPropagation1.jpg) \n",
    "\n",
    "![title](images/ForwardPropagation2.jpg) \n",
    "\n",
    "g(x)는 Activation Function\n",
    "\n",
    "순서\n",
    "1. Hidden1의 가중치합 확인\n",
    "2. Hidden1에 대하여 Activation Function으로 가중치 계산\n",
    "3. BiasWeight 추가\n",
    "4. 모든 노드에 대하여 이를 반복 실시\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackPropagation(역전파)\n",
    "\n",
    "![title](images/backwardPropagation1.jpg) \n",
    "![title](images/error2.jpg) \n",
    "\n",
    "- 가중치를 더 좋게 업데이트 하기 위함\n",
    "- Hidden Units은 Latent Variables을 나타냄\n",
    "- Output부터 역순으로 계산\n",
    "- Error = (True - Predicted Output)*(Ouput1의 편미분)\n",
    "\n",
    "\n",
    "\n",
    "![title](images/Bias1.jpg) \n",
    " \n",
    "![title](images/Bias2.jpg) \n",
    " \n",
    "\n",
    "- Error를 바탕으로 BiasWeight를 구함\n",
    "- a = Learning Rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 예시\n",
    "### 와인 데이터 활용\n",
    "https://kofboy2000.tistory.com/30\n",
    " 1. 와인 데이터 읽기\n",
    " 2. 데이터 정규화\n",
    " 3. 트레이닝\n",
    " 4. Cultivation(품종) 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler # Data Normalization\n",
    "from sklearn.neural_network import MLPClassifier # Training the model\n",
    "from sklearn.metrics import classification_report,confusion_matrix # Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "wine = pd.read_csv('C:/Users/dudwo/Desktop/wine.csv',\n",
    "                 names = [\"Cultivator\", \"Alchol\", \"Malic_Acid\", \"Ash\",\n",
    "                                             \"Alcalinity_of_Ash\", \"Magnesium\", \"Total_phenols\",\n",
    "                                             \"Falvanoids\", \"Nonflavanoid_phenols\",\n",
    "                                             \"Proanthocyanins\", \"Color_intensity\", \"Hue\",\n",
    "                                             \"OD280\", \"Proline\"])\n",
    "X = wine.drop('Cultivator',axis=1) # Input Data는 Cultivator를 제외한 나머지\n",
    "y = wine['Cultivator']             # Output Data는 Cultivator\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30)) # hidden layer 30개짜리 3개\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  1  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction and Evaluation\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.94      0.97        16\n",
      "           2       0.94      1.00      0.97        17\n",
      "           3       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
