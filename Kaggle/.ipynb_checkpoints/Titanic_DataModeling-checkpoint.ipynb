{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "train = pd.read_csv('C:/Users/dudwo/Desktop/ML/Data/titanic/train.csv')\n",
    "test = pd.read_csv('C:/Users/dudwo/Desktop/ML/Data/titanic/test.csv')\n",
    "train = train.drop(['Ticket','Cabin'],axis = 1) \n",
    "test = test.drop(['Ticket','Cabin'],axis = 1)   \n",
    "train = train.fillna({\"Embarked\" : \"S\"})\n",
    "embarked_mapping = {\"S\":1,\"C\":2,\"Q\":3}\n",
    "train[\"Embarked\"] = train[\"Embarked\"].map(embarked_mapping)\n",
    "test[\"Embarked\"] = test[\"Embarked\"].map(embarked_mapping)\n",
    "combine = [train, test]\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.',expand= False)\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(\n",
    "        ['Lady', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mile', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "title_mapping = {\"Mr\":1,\"Miss\":2,\"Mrs\":3,\"Master\":4,\"Royal\":5,\"Rare\":6}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "train = train.drop(['Name','PassengerId'],axis =1)\n",
    "test = test.drop(['Name','PassengerId'],axis =1)\n",
    "combine = [train,test]\n",
    "sex_mapping = {\"male\":0,\"female\":1}\n",
    "for dataset in combine :\n",
    "    dataset['Sex'] = dataset[\"Sex\"].map(sex_mapping)\n",
    "train['Age'] = train['Age'].fillna(-0.5)\n",
    "test['Age'] = test['Age'].fillna(-0.5)\n",
    "bins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\n",
    "labels = ['Unknown','Baby','Child','Teenager','Student','Young Adult','Adult','Senior']\n",
    "train['AgeGroup'] = pd.cut(train[\"Age\"],bins, labels= labels)\n",
    "test['AgeGroup'] = pd.cut(test[\"Age\"],bins, labels=labels)\n",
    "age_title_mapping = {1:\"Young Adult\",2:\"Student\",3:\"Adult\",4:\"Baby\",5:\"Adult\",6:\"Adult\",}\n",
    "for x in range(len(train[\"AgeGroup\"])):\n",
    "    if train[\"AgeGroup\"][x] == \"Unknown\" :\n",
    "        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n",
    "for x in range(len(test[\"AgeGroup\"])):\n",
    "    if test[\"AgeGroup\"][x] == \"Unknown\" :\n",
    "        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]\n",
    "age_mappaing = {\"Baby\":1,\"Child\":2,\"Teenager\":3,\"Student\":4,\"Young Adult\":5,\"Adult\":6,\"Senior\":7}\n",
    "train['AgeGroup'] = train['AgeGroup'].map(age_mappaing)\n",
    "test['AgeGroup'] = test['AgeGroup'].map(age_mappaing)\n",
    "train = train.drop(['Age'],axis =1)\n",
    "test = test.drop(['Age'],axis =1)\n",
    "train['FareBand'] = pd.qcut(train['Fare'], 4, labels= [1,2,3,4])\n",
    "test['FareBand'] = pd.qcut(train['Fare'],4, labels=[1,2,3,4])\n",
    "train = train.drop(['Fare'],axis = 1)\n",
    "test = test.drop(['Fare'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null int64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Embarked    891 non-null int64\n",
      "Title       891 non-null float64\n",
      "AgeGroup    891 non-null int64\n",
      "FareBand    891 non-null category\n",
      "dtypes: category(1), float64(1), int64(6)\n",
      "memory usage: 49.9 KB\n"
     ]
    }
   ],
   "source": [
    "train_data = train.drop('Survived', axis = 1)\n",
    "target = train['Survived']\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_Validation 실행\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier 실행\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "clf.fit(train_data,target)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77333333 0.73684211 0.70967742 0.71428571 0.8        0.73333333\n",
      " 0.79452055 0.78688525 0.76056338 0.73684211]\n",
      "75.46\n"
     ]
    }
   ],
   "source": [
    "# Cross_val_score 점수\n",
    "# F1 Scoring\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring = 'f1'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "print(score)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81111111 0.83146067 0.80898876 0.78651685 0.85393258 0.84269663\n",
      " 0.83146067 0.83146067 0.80898876 0.78651685]\n",
      "81.93\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Scoring\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "print(score)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82051282 0.73333333 0.67741935 0.69444444 0.7037037  0.70967742\n",
      " 0.80555556 0.77419355 0.74358974 0.66666667]\n",
      "73.29\n"
     ]
    }
   ],
   "source": [
    "# Recall Scoring\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring = 'recall'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "print(score)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74418605 0.78571429 0.6875     0.80645161 0.74074074 0.75\n",
      " 0.78378378 0.80769231 0.81818182 0.88235294]\n",
      "78.07\n"
     ]
    }
   ],
   "source": [
    "# Precision Scoring\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoring = 'precision'\n",
    "score = cross_val_score(clf,train_data,target,cv=k_fold,n_jobs=1,scoring=scoring)\n",
    "print(score)\n",
    "print(round(np.mean(score)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         1\n",
      "4            896         0\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         1\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         0\n",
      "19           911         1\n",
      "20           912         0\n",
      "21           913         1\n",
      "22           914         1\n",
      "23           915         1\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         1\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         0\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         1\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         1\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         1\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# test 파일 예측 실행\n",
    "\n",
    "# test 파일 PassengerId 열 불러오기 위함\n",
    "test2 = pd.read_csv('C:/Users/dudwo/Desktop/ML/Data/titanic/test.csv')\n",
    "\n",
    "# 예측\n",
    "prediction = clf.predict(test)\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\" : test2[\"PassengerId\"],\n",
    "    \"Survived\" : prediction\n",
    "})\n",
    "\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
